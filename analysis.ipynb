{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "1. DATA LOADING AND EXPLORATION\n",
      "============================================================\n",
      "Dataset shape: (45723, 28)\n",
      "\n",
      "Missing values:\n",
      "Drivetrain                           16824\n",
      "Vehicle Body Style                   16824\n",
      "Vehicle Engine                       16824\n",
      "Secondary Damage Type Description    24214\n",
      "Transmission Type                      650\n",
      "dtype: int64\n",
      "\n",
      "Basic statistics for numerical columns:\n",
      "           Lot Year     Sale Price  Odometer Reading   Yard Number  \\\n",
      "count  45723.000000   45723.000000      4.572300e+04  45723.000000   \n",
      "mean    2014.656803    3999.724143      1.126040e+05    124.722547   \n",
      "std        6.106087    5525.663314      9.533528e+04    108.200947   \n",
      "min     1928.000000       1.000000      0.000000e+00      1.000000   \n",
      "25%     2012.000000     875.000000      5.719900e+04     37.000000   \n",
      "50%     2015.000000    2200.000000      1.082800e+05     91.000000   \n",
      "75%     2019.000000    5000.000000      1.585090e+05    174.000000   \n",
      "max     2025.000000  184000.000000      9.592488e+06    396.000000   \n",
      "\n",
      "       LOT_SOLD_RUN   RERUN_COUNT  \n",
      "count  45723.000000  45723.000000  \n",
      "mean       1.538854      0.498239  \n",
      "std        1.756263      1.699447  \n",
      "min        1.000000      0.000000  \n",
      "25%        1.000000      0.000000  \n",
      "50%        1.000000      0.000000  \n",
      "75%        1.000000      0.000000  \n",
      "max       77.000000     74.000000  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Automobile</th>\n",
       "      <th>Lot Year</th>\n",
       "      <th>Lot Make</th>\n",
       "      <th>Lot Model</th>\n",
       "      <th>Drivetrain</th>\n",
       "      <th>Vehicle Body Style</th>\n",
       "      <th>Vehicle Engine</th>\n",
       "      <th>VIN</th>\n",
       "      <th>Invoice Date</th>\n",
       "      <th>Sale Price</th>\n",
       "      <th>...</th>\n",
       "      <th>Yard city</th>\n",
       "      <th>Yard State</th>\n",
       "      <th>Title Type</th>\n",
       "      <th>Title State</th>\n",
       "      <th>Lot Color</th>\n",
       "      <th>Transmission Type</th>\n",
       "      <th>Lot Link</th>\n",
       "      <th>Lot Fuel Type</th>\n",
       "      <th>LOT_SOLD_RUN</th>\n",
       "      <th>RERUN_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUTOMOBILE                                    ...</td>\n",
       "      <td>2024</td>\n",
       "      <td>NISS</td>\n",
       "      <td>VERSA S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3N1CN8DV8RL867765</td>\n",
       "      <td>05/26/2025</td>\n",
       "      <td>3800</td>\n",
       "      <td>...</td>\n",
       "      <td>SEAFORD</td>\n",
       "      <td>DE</td>\n",
       "      <td>S1</td>\n",
       "      <td>MD</td>\n",
       "      <td>GRAY</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>https://www.copart.com/lot/49239315</td>\n",
       "      <td>GAS                                           ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUTOMOBILE                                    ...</td>\n",
       "      <td>2022</td>\n",
       "      <td>HYUN</td>\n",
       "      <td>ELANTRA N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KMHLW4AK9NU008872</td>\n",
       "      <td>05/27/2025</td>\n",
       "      <td>7400</td>\n",
       "      <td>...</td>\n",
       "      <td>COLUMBUS</td>\n",
       "      <td>OH</td>\n",
       "      <td>ST</td>\n",
       "      <td>OH</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>https://www.copart.com/lot/54318285</td>\n",
       "      <td>GAS                                           ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUTOMOBILE                                    ...</td>\n",
       "      <td>2025</td>\n",
       "      <td>DODG</td>\n",
       "      <td>CHARGER DA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2C3CDBCK9SR543225</td>\n",
       "      <td>05/27/2025</td>\n",
       "      <td>28500</td>\n",
       "      <td>...</td>\n",
       "      <td>CHICAGO HEIGHTS</td>\n",
       "      <td>IL</td>\n",
       "      <td>CT</td>\n",
       "      <td>MI</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>https://www.copart.com/lot/49432685</td>\n",
       "      <td>ELECTRIC                                      ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUTOMOBILE                                    ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>FORD</td>\n",
       "      <td>FOCUS SEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1FADP3H24JL294433</td>\n",
       "      <td>05/26/2025</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>GRAHAM</td>\n",
       "      <td>WA</td>\n",
       "      <td>BS</td>\n",
       "      <td>WA</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>https://www.copart.com/lot/38223554</td>\n",
       "      <td>GAS                                           ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VANS/MINIVANS                                 ...</td>\n",
       "      <td>2013</td>\n",
       "      <td>TOYT</td>\n",
       "      <td>SIENNA LE</td>\n",
       "      <td>FWD</td>\n",
       "      <td>SPORTS VAN</td>\n",
       "      <td>3.5L  6</td>\n",
       "      <td>5TDKK3DC0DS353348</td>\n",
       "      <td>05/27/2025</td>\n",
       "      <td>2150</td>\n",
       "      <td>...</td>\n",
       "      <td>PENNSBURG</td>\n",
       "      <td>PA</td>\n",
       "      <td>SC</td>\n",
       "      <td>PA</td>\n",
       "      <td>SILVR</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>https://www.copart.com/lot/57671325</td>\n",
       "      <td>GAS                                           ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45718</th>\n",
       "      <td>AUTOMOBILE                                    ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NISS</td>\n",
       "      <td>KICKS S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3N1CP5CU5JL542657</td>\n",
       "      <td>05/30/2025</td>\n",
       "      <td>2650</td>\n",
       "      <td>...</td>\n",
       "      <td>DES MOINES</td>\n",
       "      <td>IA</td>\n",
       "      <td>ST</td>\n",
       "      <td>IA</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>https://www.copart.com/lot/42538725</td>\n",
       "      <td>GAS                                           ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45719</th>\n",
       "      <td>AUTOMOBILE                                    ...</td>\n",
       "      <td>2007</td>\n",
       "      <td>TOYT</td>\n",
       "      <td>COROLLA CE</td>\n",
       "      <td>FWD</td>\n",
       "      <td>SEDAN 4DR</td>\n",
       "      <td>1.8L  4</td>\n",
       "      <td>1NXBR30E47Z815523</td>\n",
       "      <td>05/28/2025</td>\n",
       "      <td>1550</td>\n",
       "      <td>...</td>\n",
       "      <td>PORTLAND</td>\n",
       "      <td>OR</td>\n",
       "      <td>SC</td>\n",
       "      <td>OR</td>\n",
       "      <td>SILVR</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>https://www.copart.com/lot/51857845</td>\n",
       "      <td>GAS                                           ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45720</th>\n",
       "      <td>SUV'S                                         ...</td>\n",
       "      <td>2023</td>\n",
       "      <td>MITS</td>\n",
       "      <td>OUTLANDER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JA4J4UA83PZ011708</td>\n",
       "      <td>05/28/2025</td>\n",
       "      <td>8100</td>\n",
       "      <td>...</td>\n",
       "      <td>COLORADO SPRINGS</td>\n",
       "      <td>CO</td>\n",
       "      <td>ST</td>\n",
       "      <td>CO</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>https://www.copart.com/lot/49513265</td>\n",
       "      <td>GAS                                           ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45721</th>\n",
       "      <td>AUTOMOBILE                                    ...</td>\n",
       "      <td>2022</td>\n",
       "      <td>HYUN</td>\n",
       "      <td>ELANTRA SE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KMHLN4AGXNU227404</td>\n",
       "      <td>05/29/2025</td>\n",
       "      <td>6400</td>\n",
       "      <td>...</td>\n",
       "      <td>COOKSTOWN</td>\n",
       "      <td>ON</td>\n",
       "      <td>ST</td>\n",
       "      <td>ON</td>\n",
       "      <td>RED</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>https://www.copart.com/lot/49952685</td>\n",
       "      <td>GAS                                           ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45722</th>\n",
       "      <td>AUTOMOBILE                                    ...</td>\n",
       "      <td>2015</td>\n",
       "      <td>VOLK</td>\n",
       "      <td>JETTA BASE</td>\n",
       "      <td>FWD</td>\n",
       "      <td>SEDAN 4DR</td>\n",
       "      <td>2  L  4</td>\n",
       "      <td>3VW2K7AJ4FM421516</td>\n",
       "      <td>05/29/2025</td>\n",
       "      <td>1100</td>\n",
       "      <td>...</td>\n",
       "      <td>COOKSTOWN</td>\n",
       "      <td>ON</td>\n",
       "      <td>ST</td>\n",
       "      <td>ON</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>https://www.copart.com/lot/52956925</td>\n",
       "      <td>GAS                                           ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45723 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Automobile  Lot Year Lot Make  \\\n",
       "0      AUTOMOBILE                                    ...      2024    NISS    \n",
       "1      AUTOMOBILE                                    ...      2022    HYUN    \n",
       "2      AUTOMOBILE                                    ...      2025    DODG    \n",
       "3      AUTOMOBILE                                    ...      2018    FORD    \n",
       "4      VANS/MINIVANS                                 ...      2013    TOYT    \n",
       "...                                                  ...       ...      ...   \n",
       "45718  AUTOMOBILE                                    ...      2018    NISS    \n",
       "45719  AUTOMOBILE                                    ...      2007    TOYT    \n",
       "45720  SUV'S                                         ...      2023    MITS    \n",
       "45721  AUTOMOBILE                                    ...      2022    HYUN    \n",
       "45722  AUTOMOBILE                                    ...      2015    VOLK    \n",
       "\n",
       "        Lot Model Drivetrain  Vehicle Body Style Vehicle Engine  \\\n",
       "0      VERSA S           NaN                 NaN            NaN   \n",
       "1      ELANTRA N         NaN                 NaN            NaN   \n",
       "2      CHARGER DA        NaN                 NaN            NaN   \n",
       "3      FOCUS SEL         NaN                 NaN            NaN   \n",
       "4      SIENNA LE         FWD  SPORTS VAN                3.5L  6   \n",
       "...           ...        ...                 ...            ...   \n",
       "45718  KICKS S           NaN                 NaN            NaN   \n",
       "45719  COROLLA CE        FWD  SEDAN 4DR                 1.8L  4   \n",
       "45720  OUTLANDER         NaN                 NaN            NaN   \n",
       "45721  ELANTRA SE        NaN                 NaN            NaN   \n",
       "45722  JETTA BASE        FWD  SEDAN 4DR                 2  L  4   \n",
       "\n",
       "                             VIN Invoice Date  Sale Price  ...  \\\n",
       "0      3N1CN8DV8RL867765           05/26/2025        3800  ...   \n",
       "1      KMHLW4AK9NU008872           05/27/2025        7400  ...   \n",
       "2      2C3CDBCK9SR543225           05/27/2025       28500  ...   \n",
       "3      1FADP3H24JL294433           05/26/2025         600  ...   \n",
       "4      5TDKK3DC0DS353348           05/27/2025        2150  ...   \n",
       "...                          ...          ...         ...  ...   \n",
       "45718  3N1CP5CU5JL542657           05/30/2025        2650  ...   \n",
       "45719  1NXBR30E47Z815523           05/28/2025        1550  ...   \n",
       "45720  JA4J4UA83PZ011708           05/28/2025        8100  ...   \n",
       "45721  KMHLN4AGXNU227404           05/29/2025        6400  ...   \n",
       "45722  3VW2K7AJ4FM421516           05/29/2025        1100  ...   \n",
       "\n",
       "                       Yard city Yard State Title Type Title State Lot Color  \\\n",
       "0      SEAFORD                           DE         S1          MD     GRAY    \n",
       "1      COLUMBUS                          OH         ST          OH     BLACK   \n",
       "2      CHICAGO HEIGHTS                   IL         CT          MI     BLACK   \n",
       "3      GRAHAM                            WA         BS          WA     WHITE   \n",
       "4      PENNSBURG                         PA         SC          PA     SILVR   \n",
       "...                          ...        ...        ...         ...       ...   \n",
       "45718  DES MOINES                        IA         ST          IA     WHITE   \n",
       "45719  PORTLAND                          OR         SC          OR     SILVR   \n",
       "45720  COLORADO SPRINGS                  CO         ST          CO     BLACK   \n",
       "45721  COOKSTOWN                         ON         ST          ON     RED     \n",
       "45722  COOKSTOWN                         ON         ST          ON     WHITE   \n",
       "\n",
       "       Transmission Type                             Lot Link  \\\n",
       "0              Automatic  https://www.copart.com/lot/49239315   \n",
       "1              Automatic  https://www.copart.com/lot/54318285   \n",
       "2              Automatic  https://www.copart.com/lot/49432685   \n",
       "3              Automatic  https://www.copart.com/lot/38223554   \n",
       "4              Automatic  https://www.copart.com/lot/57671325   \n",
       "...                  ...                                  ...   \n",
       "45718          Automatic  https://www.copart.com/lot/42538725   \n",
       "45719          Automatic  https://www.copart.com/lot/51857845   \n",
       "45720          Automatic  https://www.copart.com/lot/49513265   \n",
       "45721          Automatic  https://www.copart.com/lot/49952685   \n",
       "45722          Automatic  https://www.copart.com/lot/52956925   \n",
       "\n",
       "                                           Lot Fuel Type LOT_SOLD_RUN  \\\n",
       "0      GAS                                           ...            3   \n",
       "1      GAS                                           ...            1   \n",
       "2      ELECTRIC                                      ...            1   \n",
       "3      GAS                                           ...            2   \n",
       "4      GAS                                           ...            1   \n",
       "...                                                  ...          ...   \n",
       "45718  GAS                                           ...            1   \n",
       "45719  GAS                                           ...            1   \n",
       "45720  GAS                                           ...            1   \n",
       "45721  GAS                                           ...            1   \n",
       "45722  GAS                                           ...            1   \n",
       "\n",
       "      RERUN_COUNT  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               1  \n",
       "4               0  \n",
       "...           ...  \n",
       "45718           0  \n",
       "45719           0  \n",
       "45720           0  \n",
       "45721           0  \n",
       "45722           0  \n",
       "\n",
       "[45723 rows x 28 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 1. DATA LOADING AND INITIAL EXPLORATION\n",
    "# ============================================================================\n",
    "\n",
    "def load_and_explore_data(file_path='data.csv'):\n",
    "    \"\"\"\n",
    "    Load the dataset and perform initial exploration\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"1. DATA LOADING AND EXPLORATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # # Based on the sample data, let's define column names\n",
    "    # column_names = [\n",
    "    #     'vehicle_type', 'year', 'make', 'model', 'body_style', 'model_group', \n",
    "    #     'series', 'vin', 'sale_date', 'odometer', 'run_and_drive', 'title_type',\n",
    "    #     'damage_primary', 'damage_secondary', 'zip_code', 'sale_price', 'lot_number',\n",
    "    #     'location_city', 'location_state_full', 'location_state', 'grade', \n",
    "    #     'location_country', 'color', 'transmission', 'image_url', 'fuel_type',\n",
    "    #     'keys', 'notes'\n",
    "    # ]\n",
    "    \n",
    "    # # Assign column names if they don't exist\n",
    "    # if len(df.columns) == len(column_names):\n",
    "    #     df.columns = column_names\n",
    "    \n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    # print(f\"Dataset info:\")\n",
    "    # print(df.info())\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(f\"\\nMissing values:\")\n",
    "    missing_values = df.isnull().sum()\n",
    "    print(missing_values[missing_values > 0])\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"\\nBasic statistics for numerical columns:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = load_and_explore_data('data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "2. DATA PREPROCESSING AND CLEANING\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "['sale_price']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/var/folders/rf/r785zb1d6vvc7r4lhhwz6t3h0000gq/T/ipykernel_90191/2220750040.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     55\u001b[39m     print(\u001b[33mf\"Final dataset shape after preprocessing: {df_processed.shape}\"\u001b[39m)\n\u001b[32m     56\u001b[39m \n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df_processed\n\u001b[32m     58\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m df_processed = preprocess_data(df)\n\u001b[32m     60\u001b[39m df_processed\n",
      "\u001b[32m/var/folders/rf/r785zb1d6vvc7r4lhhwz6t3h0000gq/T/ipykernel_90191/2220750040.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     15\u001b[39m \n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# Clean sale_price (target variable)\u001b[39;00m\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# Remove rows where sale_price is null or zero\u001b[39;00m\n\u001b[32m     18\u001b[39m     initial_rows = len(df_processed)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     df_processed = df_processed.dropna(subset=[\u001b[33m'sale_price'\u001b[39m])\n\u001b[32m     20\u001b[39m     df_processed = df_processed[df_processed[\u001b[33m'sale_price'\u001b[39m] > \u001b[32m0\u001b[39m]\n\u001b[32m     21\u001b[39m     print(\u001b[33mf\"Removed {initial_rows - len(df_processed)} rows with invalid sale prices\"\u001b[39m)\n\u001b[32m     22\u001b[39m \n",
      "\u001b[32m~/.pyenv/versions/3.11.6/envs/my-vscode-env/lib/python3.11/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[39m\n\u001b[32m   6666\u001b[39m             ax = self._get_axis(agg_axis)\n\u001b[32m   6667\u001b[39m             indices = ax.get_indexer_for(subset)\n\u001b[32m   6668\u001b[39m             check = indices == -\u001b[32m1\u001b[39m\n\u001b[32m   6669\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m check.any():\n\u001b[32m-> \u001b[39m\u001b[32m6670\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m KeyError(np.array(subset)[check].tolist())\n\u001b[32m   6671\u001b[39m             agg_obj = self.take(indices, axis=agg_axis)\n\u001b[32m   6672\u001b[39m \n\u001b[32m   6673\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m thresh \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default:\n",
      "\u001b[31mKeyError\u001b[39m: ['sale_price']"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2. DATA PREPROCESSING AND CLEANING\n",
    "# ============================================================================\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Clean and preprocess the data\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"2. DATA PREPROCESSING AND CLEANING\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create a copy to avoid modifying original data\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Clean sale_price (target variable)\n",
    "    # Remove rows where sale_price is null or zero\n",
    "    initial_rows = len(df_processed)\n",
    "    df_processed = df_processed.dropna(subset=['Sale Price'])\n",
    "    df_processed = df_processed[df_processed['Sale Price'] > 0]\n",
    "    print(f\"Removed {initial_rows - len(df_processed)} rows with invalid sale prices\")\n",
    "    \n",
    "    # Clean year column\n",
    "    df_processed['Lot Year'] = pd.to_numeric(df_processed['Lot Year'], errors='coerce')\n",
    "    df_processed = df_processed[df_processed['Lot Year'].between(1980, 2025)]\n",
    "    \n",
    "    # Clean odometer readings\n",
    "    df_processed['Odometer Reading'] = pd.to_numeric(df_processed['Odometer Reading'], errors='coerce')\n",
    "    # Replace unrealistic odometer readings\n",
    "    df_processed.loc[df_processed['Odometer Reading'] > 500000, 'Odometer Reading'] = np.nan\n",
    "    \n",
    "    # Clean and standardize categorical variables\n",
    "    categorical_columns = ['make', 'model', 'color', 'transmission', 'fuel_type', \n",
    "                          'run_and_drive', 'title_type', 'damage_primary', 'location_state']\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        if col in df_processed.columns:\n",
    "            df_processed[col] = df_processed[col].astype(str).str.strip().str.upper()\n",
    "    \n",
    "    # Create vehicle age feature\n",
    "    df_processed['vehicle_age'] = 2025 - df_processed['year']\n",
    "    \n",
    "    # Extract useful features from VIN (if available)\n",
    "    if 'vin' in df_processed.columns:\n",
    "        df_processed['vin_length'] = df_processed['vin'].astype(str).str.len()\n",
    "    \n",
    "    # Create damage severity feature\n",
    "    if 'damage_primary' in df_processed.columns:\n",
    "        df_processed['has_damage'] = df_processed['damage_primary'].notna().astype(int)\n",
    "    \n",
    "    # Clean location data\n",
    "    if 'location_state' in df_processed.columns:\n",
    "        df_processed['location_state'] = df_processed['location_state'].fillna('UNKNOWN')\n",
    "    \n",
    "    print(f\"Final dataset shape after preprocessing: {df_processed.shape}\")\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "df_processed = preprocess_data(df)\n",
    "df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 3. EXPLORATORY DATA ANALYSIS (EDA)\n",
    "# ============================================================================\n",
    "\n",
    "def perform_eda(df):\n",
    "    \"\"\"\n",
    "    Perform exploratory data analysis\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"3. EXPLORATORY DATA ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Set up the plotting style\n",
    "    plt.style.use('default')\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # 1. Distribution of target variable (sale_price)\n",
    "    axes[0, 0].hist(df['sale_price'], bins=50, alpha=0.7, color='skyblue')\n",
    "    axes[0, 0].set_title('Distribution of Sale Prices')\n",
    "    axes[0, 0].set_xlabel('Sale Price ($)')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    \n",
    "    # 2. Sale price vs Vehicle Age\n",
    "    if 'vehicle_age' in df.columns:\n",
    "        axes[0, 1].scatter(df['vehicle_age'], df['sale_price'], alpha=0.5, color='green')\n",
    "        axes[0, 1].set_title('Sale Price vs Vehicle Age')\n",
    "        axes[0, 1].set_xlabel('Vehicle Age (years)')\n",
    "        axes[0, 1].set_ylabel('Sale Price ($)')\n",
    "    \n",
    "    # 3. Sale price vs Odometer\n",
    "    if 'odometer' in df.columns:\n",
    "        valid_odometer = df.dropna(subset=['odometer'])\n",
    "        axes[0, 2].scatter(valid_odometer['odometer'], valid_odometer['sale_price'], \n",
    "                          alpha=0.5, color='red')\n",
    "        axes[0, 2].set_title('Sale Price vs Odometer Reading')\n",
    "        axes[0, 2].set_xlabel('Odometer (miles)')\n",
    "        axes[0, 2].set_ylabel('Sale Price ($)')\n",
    "    \n",
    "    # 4. Average sale price by make (top 10)\n",
    "    if 'make' in df.columns:\n",
    "        make_prices = df.groupby('make')['sale_price'].agg(['mean', 'count']).reset_index()\n",
    "        make_prices = make_prices[make_prices['count'] >= 10].sort_values('mean', ascending=False).head(10)\n",
    "        axes[1, 0].bar(range(len(make_prices)), make_prices['mean'], color='orange')\n",
    "        axes[1, 0].set_title('Average Sale Price by Make (Top 10)')\n",
    "        axes[1, 0].set_xlabel('Make')\n",
    "        axes[1, 0].set_ylabel('Average Sale Price ($)')\n",
    "        axes[1, 0].set_xticks(range(len(make_prices)))\n",
    "        axes[1, 0].set_xticklabels(make_prices['make'], rotation=45, ha='right')\n",
    "    \n",
    "    # 5. Sale price by transmission type\n",
    "    if 'transmission' in df.columns:\n",
    "        trans_prices = df.groupby('transmission')['sale_price'].mean().sort_values(ascending=False)\n",
    "        axes[1, 1].bar(range(len(trans_prices)), trans_prices.values, color='purple')\n",
    "        axes[1, 1].set_title('Average Sale Price by Transmission')\n",
    "        axes[1, 1].set_xlabel('Transmission Type')\n",
    "        axes[1, 1].set_ylabel('Average Sale Price ($)')\n",
    "        axes[1, 1].set_xticks(range(len(trans_prices)))\n",
    "        axes[1, 1].set_xticklabels(trans_prices.index, rotation=45, ha='right')\n",
    "    \n",
    "    # 6. Correlation heatmap for numerical features\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    correlation_matrix = df[numerical_cols].corr()\n",
    "    im = axes[1, 2].imshow(correlation_matrix, cmap='coolwarm', aspect='auto')\n",
    "    axes[1, 2].set_title('Correlation Matrix')\n",
    "    axes[1, 2].set_xticks(range(len(numerical_cols)))\n",
    "    axes[1, 2].set_yticks(range(len(numerical_cols)))\n",
    "    axes[1, 2].set_xticklabels(numerical_cols, rotation=45, ha='right')\n",
    "    axes[1, 2].set_yticklabels(numerical_cols)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print key insights\n",
    "    print(f\"\\nKey Insights:\")\n",
    "    print(f\"- Average sale price: ${df['sale_price'].mean():.2f}\")\n",
    "    print(f\"- Median sale price: ${df['sale_price'].median():.2f}\")\n",
    "    print(f\"- Price range: ${df['sale_price'].min():.2f} - ${df['sale_price'].max():.2f}\")\n",
    "    \n",
    "    if 'vehicle_age' in df.columns:\n",
    "        correlation = df['vehicle_age'].corr(df['sale_price'])\n",
    "        print(f\"- Correlation between vehicle age and price: {correlation:.3f}\")\n",
    "    \n",
    "    if 'odometer' in df.columns:\n",
    "        correlation = df['odometer'].corr(df['sale_price'])\n",
    "        print(f\"- Correlation between odometer and price: {correlation:.3f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "\n",
    "def engineer_features(df):\n",
    "    \"\"\"\n",
    "    Create new features and prepare data for modeling\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"4. FEATURE ENGINEERING\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    df_features = df.copy()\n",
    "    \n",
    "    # 1. Price per mile (if odometer available)\n",
    "    if 'odometer' in df_features.columns:\n",
    "        df_features['price_per_mile'] = df_features['sale_price'] / (df_features['odometer'] + 1)\n",
    "    \n",
    "    # 2. Luxury brand indicator\n",
    "    luxury_brands = ['BMW', 'MERCEDES', 'AUDI', 'LEXUS', 'INFINITI', 'ACURA', 'CADILLAC']\n",
    "    if 'make' in df_features.columns:\n",
    "        df_features['is_luxury'] = df_features['make'].isin(luxury_brands).astype(int)\n",
    "    \n",
    "    # 3. Popular model indicator (models with >50 entries)\n",
    "    if 'model' in df_features.columns:\n",
    "        model_counts = df_features['model'].value_counts()\n",
    "        popular_models = model_counts[model_counts > 50].index\n",
    "        df_features['is_popular_model'] = df_features['model'].isin(popular_models).astype(int)\n",
    "    \n",
    "    # 4. Damage severity score\n",
    "    if 'damage_primary' in df_features.columns:\n",
    "        damage_severity = {\n",
    "            'MINOR': 1, 'MODERATE': 2, 'MAJOR': 3, 'SEVERE': 4,\n",
    "            'FRONT': 2, 'REAR': 2, 'SIDE': 2, 'ALL OVER': 4\n",
    "        }\n",
    "        df_features['damage_severity'] = df_features['damage_primary'].map(damage_severity).fillna(0)\n",
    "    \n",
    "    # 5. Age groups\n",
    "    if 'vehicle_age' in df_features.columns:\n",
    "        df_features['age_group'] = pd.cut(df_features['vehicle_age'], \n",
    "                                         bins=[0, 3, 7, 15, 100], \n",
    "                                         labels=['New', 'Recent', 'Older', 'Classic'])\n",
    "    \n",
    "    # 6. Mileage groups\n",
    "    if 'odometer' in df_features.columns:\n",
    "        df_features['mileage_group'] = pd.cut(df_features['odometer'], \n",
    "                                             bins=[0, 30000, 75000, 150000, 500000], \n",
    "                                             labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "    \n",
    "    print(f\"Features engineered. New dataset shape: {df_features.shape}\")\n",
    "    print(f\"New features created: price_per_mile, is_luxury, is_popular_model, damage_severity, age_group, mileage_group\")\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "# ============================================================================\n",
    "# 5. MODEL PREPARATION\n",
    "# ============================================================================\n",
    "\n",
    "def prepare_model_data(df):\n",
    "    \"\"\"\n",
    "    Prepare data for machine learning models\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"5. MODEL PREPARATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Define target variable\n",
    "    target = 'sale_price'\n",
    "    \n",
    "    # Define features to use\n",
    "    numerical_features = ['year', 'odometer', 'vehicle_age', 'damage_severity']\n",
    "    categorical_features = ['make', 'transmission', 'fuel_type', 'run_and_drive', \n",
    "                           'title_type', 'location_state', 'color']\n",
    "    \n",
    "    # Filter features that actually exist in the dataset\n",
    "    numerical_features = [f for f in numerical_features if f in df.columns]\n",
    "    categorical_features = [f for f in categorical_features if f in df.columns]\n",
    "    \n",
    "    # Add engineered features if they exist\n",
    "    if 'is_luxury' in df.columns:\n",
    "        numerical_features.append('is_luxury')\n",
    "    if 'is_popular_model' in df.columns:\n",
    "        numerical_features.append('is_popular_model')\n",
    "    \n",
    "    all_features = numerical_features + categorical_features\n",
    "    \n",
    "    # Prepare X and y\n",
    "    X = df[all_features].copy()\n",
    "    y = df[target].copy()\n",
    "    \n",
    "    # Remove rows with missing target values\n",
    "    mask = ~y.isna()\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    \n",
    "    print(f\"Features selected:\")\n",
    "    print(f\"- Numerical features: {numerical_features}\")\n",
    "    print(f\"- Categorical features: {categorical_features}\")\n",
    "    print(f\"Final dataset shape: {X.shape}\")\n",
    "    \n",
    "    return X, y, numerical_features, categorical_features\n",
    "\n",
    "# ============================================================================\n",
    "# 6. MODEL TRAINING AND EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "def train_and_evaluate_models(X, y, numerical_features, categorical_features):\n",
    "    \"\"\"\n",
    "    Train multiple models and evaluate their performance\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"6. MODEL TRAINING AND EVALUATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create preprocessing pipelines\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "    \n",
    "    # Combine preprocessing steps\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "    \n",
    "    # Define models to try\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Ridge Regression': Ridge(alpha=1.0),\n",
    "        'Lasso Regression': Lasso(alpha=1.0),\n",
    "        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "        'Decision Tree': DecisionTreeRegressor(random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Store results\n",
    "    model_results = {}\n",
    "    trained_models = {}\n",
    "    \n",
    "    print(\"Training models...\")\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "        \n",
    "        # Create pipeline\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', model)\n",
    "        ])\n",
    "        \n",
    "        # Train model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_train = pipeline.predict(X_train)\n",
    "        y_pred_test = pipeline.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "        train_r2 = r2_score(y_train, y_pred_train)\n",
    "        test_r2 = r2_score(y_test, y_pred_test)\n",
    "        test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "        \n",
    "        # Cross-validation score\n",
    "        cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, \n",
    "                                   scoring='neg_root_mean_squared_error')\n",
    "        cv_rmse = -cv_scores.mean()\n",
    "        \n",
    "        # Store results\n",
    "        model_results[model_name] = {\n",
    "            'Train RMSE': train_rmse,\n",
    "            'Test RMSE': test_rmse,\n",
    "            'Train R²': train_r2,\n",
    "            'Test R²': test_r2,\n",
    "            'Test MAE': test_mae,\n",
    "            'CV RMSE': cv_rmse\n",
    "        }\n",
    "        \n",
    "        trained_models[model_name] = pipeline\n",
    "        \n",
    "        print(f\"  Test RMSE: ${test_rmse:.2f}\")\n",
    "        print(f\"  Test R²: {test_r2:.4f}\")\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame(model_results).T\n",
    "    print(f\"\\nModel Comparison:\")\n",
    "    print(results_df.round(2))\n",
    "    \n",
    "    # Find best model\n",
    "    best_model_name = results_df['Test R²'].idxmax()\n",
    "    best_model = trained_models[best_model_name]\n",
    "    \n",
    "    print(f\"\\nBest model: {best_model_name}\")\n",
    "    print(f\"Best model Test R²: {results_df.loc[best_model_name, 'Test R²']:.4f}\")\n",
    "    \n",
    "    return trained_models, results_df, best_model, best_model_name, X_test, y_test\n",
    "\n",
    "# ============================================================================\n",
    "# 7. MODEL INTERPRETATION AND FEATURE IMPORTANCE\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_model_performance(best_model, best_model_name, X_test, y_test, numerical_features, categorical_features):\n",
    "    \"\"\"\n",
    "    Analyze the best model's performance and feature importance\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"7. MODEL INTERPRETATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Actual vs Predicted\n",
    "    axes[0, 0].scatter(y_test, y_pred, alpha=0.6)\n",
    "    axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    axes[0, 0].set_xlabel('Actual Price')\n",
    "    axes[0, 0].set_ylabel('Predicted Price')\n",
    "    axes[0, 0].set_title('Actual vs Predicted Prices')\n",
    "    \n",
    "    # 2. Residuals plot\n",
    "    residuals = y_test - y_pred\n",
    "    axes[0, 1].scatter(y_pred, residuals, alpha=0.6)\n",
    "    axes[0, 1].axhline(y=0, color='r', linestyle='--')\n",
    "    axes[0, 1].set_xlabel('Predicted Price')\n",
    "    axes[0, 1].set_ylabel('Residuals')\n",
    "    axes[0, 1].set_title('Residuals Plot')\n",
    "    \n",
    "    # 3. Feature importance (if available)\n",
    "    if hasattr(best_model.named_steps['regressor'], 'feature_importances_'):\n",
    "        # Get feature names after preprocessing\n",
    "        preprocessor = best_model.named_steps['preprocessor']\n",
    "        feature_names = (numerical_features + \n",
    "                        list(preprocessor.named_transformers_['cat']\n",
    "                            .named_steps['onehot'].get_feature_names_out(categorical_features)))\n",
    "        \n",
    "        importances = best_model.named_steps['regressor'].feature_importances_\n",
    "        \n",
    "        # Get top 15 features\n",
    "        top_indices = np.argsort(importances)[-15:]\n",
    "        top_features = [feature_names[i] for i in top_indices]\n",
    "        top_importances = importances[top_indices]\n",
    "        \n",
    "        axes[1, 0].barh(range(len(top_features)), top_importances)\n",
    "        axes[1, 0].set_yticks(range(len(top_features)))\n",
    "        axes[1, 0].set_yticklabels(top_features)\n",
    "        axes[1, 0].set_xlabel('Feature Importance')\n",
    "        axes[1, 0].set_title('Top 15 Feature Importances')\n",
    "    \n",
    "    # 4. Distribution of residuals\n",
    "    axes[1, 1].hist(residuals, bins=30, alpha=0.7, color='skyblue')\n",
    "    axes[1, 1].set_xlabel('Residuals')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].set_title('Distribution of Residuals')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\nFinal Model Performance ({best_model_name}):\")\n",
    "    print(f\"- RMSE: ${rmse:.2f}\")\n",
    "    print(f\"- MAE: ${mae:.2f}\")\n",
    "    print(f\"- R² Score: {r2:.4f}\")\n",
    "    print(f\"- Mean Actual Price: ${y_test.mean():.2f}\")\n",
    "    print(f\"- Mean Predicted Price: ${y_pred.mean():.2f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 8. PREDICTION FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def make_predictions(model, X_sample):\n",
    "    \"\"\"\n",
    "    Make predictions on new data\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"8. MAKING PREDICTIONS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    predictions = model.predict(X_sample)\n",
    "    \n",
    "    print(f\"Predictions for sample data:\")\n",
    "    for i, pred in enumerate(predictions[:5]):  # Show first 5 predictions\n",
    "        print(f\"Sample {i+1}: ${pred:.2f}\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# ============================================================================\n",
    "# 9. MODEL HYPERPARAMETER TUNING\n",
    "# ============================================================================\n",
    "\n",
    "def tune_best_model(best_model_name, X_train, y_train, numerical_features, categorical_features):\n",
    "    \"\"\"\n",
    "    Perform hyperparameter tuning on the best model\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"9. HYPERPARAMETER TUNING\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create preprocessing pipeline\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "    \n",
    "    # Define parameter grids for different models\n",
    "    param_grids = {\n",
    "        'Random Forest': {\n",
    "            'regressor__n_estimators': [100, 200],\n",
    "            'regressor__max_depth': [10, 20, None],\n",
    "            'regressor__min_samples_split': [2, 5],\n",
    "            'regressor__min_samples_leaf': [1, 2]\n",
    "        },\n",
    "        'Gradient Boosting': {\n",
    "            'regressor__n_estimators': [100, 200],\n",
    "            'regressor__learning_rate': [0.05, 0.1, 0.2],\n",
    "            'regressor__max_depth': [3, 5, 7]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if best_model_name in param_grids:\n",
    "        print(f\"Tuning {best_model_name}...\")\n",
    "        \n",
    "        # Create model\n",
    "        if best_model_name == 'Random Forest':\n",
    "            model = RandomForestRegressor(random_state=42)\n",
    "        elif best_model_name == 'Gradient Boosting':\n",
    "            model = GradientBoostingRegressor(random_state=42)\n",
    "        \n",
    "        # Create pipeline\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', model)\n",
    "        ])\n",
    "        \n",
    "        # Perform grid search\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline, \n",
    "            param_grids[best_model_name], \n",
    "            cv=3, \n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best CV score: {-grid_search.best_score_:.2f}\")\n",
    "        \n",
    "        return grid_search.best_estimator_\n",
    "    \n",
    "    else:\n",
    "        print(f\"No hyperparameter tuning defined for {best_model_name}\")\n",
    "        return None\n",
    "\n",
    "# ============================================================================\n",
    "# 10. MAIN EXECUTION FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the complete ML pipeline\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Load and explore data\n",
    "        df = load_and_explore_data('data.csv')\n",
    "        \n",
    "        # Step 2: Preprocess data\n",
    "        df_processed = preprocess_data(df)\n",
    "        \n",
    "        # Step 3: Exploratory Data Analysis\n",
    "        perform_eda(df_processed)\n",
    "        \n",
    "        # Step 4: Feature Engineering\n",
    "        df_features = engineer_features(df_processed)\n",
    "        \n",
    "        # Step 5: Prepare data for modeling\n",
    "        X, y, numerical_features, categorical_features = prepare_model_data(df_features)\n",
    "        \n",
    "        # Step 6: Train and evaluate models\n",
    "        trained_models, results_df, best_model, best_model_name, X_test, y_test = train_and_evaluate_models(\n",
    "            X, y, numerical_features, categorical_features\n",
    "        )\n",
    "        \n",
    "        # Step 7: Analyze best model performance\n",
    "        analyze_model_performance(best_model, best_model_name, X_test, y_test, \n",
    "                                 numerical_features, categorical_features)\n",
    "        \n",
    "        # Step 8: Make sample predictions\n",
    "        sample_predictions = make_predictions(best_model, X_test.head(5))\n",
    "        \n",
    "        # Step 9: Hyperparameter tuning (optional)\n",
    "        X_train = X.drop(X_test.index)\n",
    "        y_train = y.drop(X_test.index)\n",
    "        tuned_model = tune_best_model(best_model_name, X_train, y_train, \n",
    "                                     numerical_features, categorical_features)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        return {\n",
    "            'best_model': best_model,\n",
    "            'tuned_model': tuned_model,\n",
    "            'results': results_df,\n",
    "            'preprocessed_data': df_features\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in pipeline: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# ============================================================================\n",
    "# 11. UTILITY FUNCTIONS FOR PRODUCTION\n",
    "# ============================================================================\n",
    "\n",
    "def save_model(model, filename):\n",
    "    \"\"\"\n",
    "    Save the trained model\n",
    "    \"\"\"\n",
    "    import joblib\n",
    "    joblib.dump(model, filename)\n",
    "    print(f\"Model saved as {filename}\")\n",
    "\n",
    "def load_model(filename):\n",
    "    \"\"\"\n",
    "    Load a saved model\n",
    "    \"\"\"\n",
    "    import joblib\n",
    "    return joblib.load(filename)\n",
    "\n",
    "def predict_single_vehicle(model, vehicle_data):\n",
    "    \"\"\"\n",
    "    Predict price for a single vehicle\n",
    "    \n",
    "    Example usage:\n",
    "    vehicle_data = {\n",
    "        'year': 2020,\n",
    "        'make': 'TOYOTA',\n",
    "        'model': 'CAMRY',\n",
    "        'odometer': 50000,\n",
    "        'transmission': 'AUTOMATIC',\n",
    "        'fuel_type': 'GAS',\n",
    "        'run_and_drive': 'YES',\n",
    "        'title_type': 'CLEAN',\n",
    "        'location_state': 'CA',\n",
    "        'color': 'WHITE'\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Convert to DataFrame\n",
    "    df_single = pd.DataFrame([vehicle_data])\n",
    "    \n",
    "    # Add derived features\n",
    "    if 'year' in df_single.columns:\n",
    "        df_single['vehicle_age'] = 2025 - df_single['year']\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(df_single)\n",
    "    return prediction[0]\n",
    "\n",
    "# ============================================================================\n",
    "# EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the complete pipeline\n",
    "    results = main()\n",
    "    \n",
    "    # Example of how to use the trained model\n",
    "    if results and results['best_model']:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"EXAMPLE PREDICTION\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Example vehicle data\n",
    "        example_vehicle = {\n",
    "            'year': 2020,\n",
    "            'make': 'TOYOTA',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # That's an excellent request\\! Providing \"the complete code\" for an ideal sales price prediction problem is a fantastic goal, but it's important to understand a few things up front:\n",
    "\n",
    "# 1.  **\"Complete Code\" is Context-Dependent:** A truly \"complete\" production-ready solution would involve:\n",
    "\n",
    "#       * Sophisticated data ingestion from various sources (databases, APIs, web).\n",
    "#       * Robust error handling and logging.\n",
    "#       * Advanced feature engineering specific to the domain (e.g., real estate, cars, retail goods).\n",
    "#       * A full-fledged MLOps pipeline for deployment, monitoring, and retraining.\n",
    "#       * A user interface or API for predictions.\n",
    "#       * These elements are highly specific to the project's real-world constraints and data.\n",
    "\n",
    "# 2.  **Focus on the Core ML Pipeline:** For a single Python script, I'll focus on demonstrating the *core machine learning pipeline* from data loading to model evaluation, assuming a clean dataset is readily available.\n",
    "\n",
    "# 3.  **Illustrative Example:** I'll create a synthetic dataset that mimics some characteristics of real-world sales data (e.g., property sales, car sales) to make the example runnable and understandable without needing to download external files.\n",
    "\n",
    "# 4.  **Key Libraries:** We'll use standard libraries like `pandas` for data manipulation, `numpy` for numerical operations, `scikit-learn` for machine learning algorithms and preprocessing, and `matplotlib`/`seaborn` for visualization.\n",
    "\n",
    "# -----\n",
    "\n",
    "# Here's the Python code covering the essential steps, with detailed comments and explanations within the code itself.\n",
    "\n",
    "# ```python -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my-vscode-env)",
   "language": "python",
   "name": "my-vscode-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
